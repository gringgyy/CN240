{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, confusion_matrix, roc_curve, auc, plot_roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from PIL import Image\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.compat.v1 import ConfigProto\n",
    "from tensorflow.compat.v1 import InteractiveSession\n",
    "import warnings\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "warnings.simplefilter('error', Image.DecompressionBombWarning)\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "from PIL import Image\n",
    "Image.MAX_IMAGE_PIXELS = 1000000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "session = InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetFolderName='dataset'\n",
    "MODEL_FILENAME=\"model_dl.h5\"\n",
    "sourceFiles=[]\n",
    "classLabels=['glaucoma', 'normal', 'other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transferBetweenFolders(source, dest, splitRate):   \n",
    "    global sourceFiles\n",
    "    sourceFiles=os.listdir(source)\n",
    "    if(len(sourceFiles)!=0):\n",
    "        transferFileNumbers=int(len(sourceFiles)*splitRate)\n",
    "        transferIndex=random.sample(range(0, len(sourceFiles)), transferFileNumbers)\n",
    "        for eachIndex in transferIndex:\n",
    "            shutil.move(source+str(sourceFiles[eachIndex]), dest+str(sourceFiles[eachIndex]))\n",
    "    else:\n",
    "        print(\"No file moved. Source empty!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transferAllClassBetweenFolders(source, dest, splitRate):\n",
    "    for label in classLabels:\n",
    "        transferBetweenFolders(datasetFolderName+'/'+source+'/'+label+'/', \n",
    "                               datasetFolderName+'/'+dest+'/'+label+'/', \n",
    "                               splitRate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No file moved. Source empty!\n",
      "No file moved. Source empty!\n",
      "No file moved. Source empty!\n"
     ]
    }
   ],
   "source": [
    "# First, check if test folder is empty or not, if not transfer all existing files to train\n",
    "transferAllClassBetweenFolders('test', 'train', 1.0)\n",
    "# Now, split some part of train data into the test folders.\n",
    "transferAllClassBetweenFolders('train', 'test', 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "Y=[]\n",
    "def prepareNameWithLabels(folderName):\n",
    "    sourceFiles=os.listdir(datasetFolderName+'/train/'+folderName+'/')\n",
    "    for val in sourceFiles:\n",
    "        X.append(val)\n",
    "        if(folderName==classLabels[0]):\n",
    "            Y.append(0)\n",
    "        elif(folderName==classLabels[1]):\n",
    "            Y.append(1)\n",
    "        else:\n",
    "            Y.append(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepareNameWithLabels(classLabels[0])\n",
    "prepareNameWithLabels(classLabels[1])\n",
    "prepareNameWithLabels(classLabels[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.asarray(X)\n",
    "Y=np.asarray(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "batch_size = 5\n",
    "epoch=5\n",
    "activationFunction='relu'\n",
    "def Model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(64, (3, 3), padding='same', activation=activationFunction, input_shape=(img_rows, img_cols, 3)))\n",
    "    model.add(Conv2D(64, (3, 3), activation=activationFunction))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    " \n",
    "    model.add(Conv2D(32, (3, 3), padding='same', activation=activationFunction))\n",
    "    model.add(Conv2D(32, (3, 3), activation=activationFunction))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    " \n",
    "    model.add(Conv2D(16, (3, 3), padding='same', activation=activationFunction))\n",
    "    model.add(Conv2D(16, (3, 3), activation=activationFunction))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    " \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation=activationFunction)) # we can drop \n",
    "    model.add(Dropout(0.1))                  # this layers\n",
    "    model.add(Dense(32, activation=activationFunction))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(16, activation=activationFunction))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(3, activation='softmax')) \n",
    "    \n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_metrics(y_true, y_pred):\n",
    "    accuracy=accuracy_score(y_true, y_pred)\n",
    "    precision=precision_score(y_true, y_pred,average='weighted')\n",
    "    f1Score=f1_score(y_true, y_pred, average='weighted')\n",
    "    cm=confusion_matrix(y_true, y_pred)\n",
    "    sensGlacoma = cm[0][0]/(cm[0][0]+cm[0][1]+cm[0][2])\n",
    "    specGlaucoma = (cm[1][1]+cm[1][2]+cm[2][1]+cm[2][2])/(cm[1][1]+cm[1][2]+cm[2][1]+cm[2][2]+cm[1][0]+cm[2][0])\n",
    "    sensNormal = cm[1][1]/(cm[1][0]+cm[1][1]+cm[1][2])\n",
    "    specNormal = (cm[0][0]+cm[0][2]+cm[2][0]+cm[2][2])/(cm[0][1]+cm[2][1]+cm[0][0]+cm[0][2]+cm[2][0]+cm[2][2])\n",
    "    sensOther = cm[2][2]/(cm[0][2]+cm[1][2]+cm[2][2])\n",
    "    specOther = (cm[0][0]+cm[0][1]+cm[1][0]+cm[1][1])/(cm[0][2]+cm[1][2]+cm[0][0]+cm[0][1]+cm[1][0]+cm[1][1])\n",
    "    \n",
    "    print(\"Accuracy  : {}\".format(accuracy))\n",
    "    print(\"Precision : {}\".format(precision))\n",
    "    print(\"f1Score : {}\".format(f1Score))\n",
    "    print(\"sensGlacoma : {}\".format(sensGlacoma))\n",
    "    print(\"specGlaucoma : {}\".format(specGlaucoma))\n",
    "    print(\"sensNormal : {}\".format(sensNormal))\n",
    "    print(\"specNormal : {}\".format(specNormal))\n",
    "    print(\"sensOther : {}\".format(sensOther))\n",
    "    print(\"specOther : {}\".format(specOther))\n",
    "    \n",
    "    print(cm)\n",
    "    return accuracy, precision, f1Score, sensGlacoma, specGlaucoma, sensNormal, specNormal, sensOther, specOther"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols =  224, 224\n",
    "\n",
    "train_path=datasetFolderName+'/train/'\n",
    "validation_path=datasetFolderName+'/validation/'\n",
    "test_path=datasetFolderName+'/test/'\n",
    "model=Model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No file moved. Source empty!\n",
      "No file moved. Source empty!\n",
      "No file moved. Source empty!\n",
      "Results for fold 1\n",
      "Found 15008 images belonging to 3 classes.\n",
      "Found 3752 images belonging to 3 classes.\n",
      "Epoch 1/5\n",
      "3002/3002 [==============================] - 1919s 639ms/step - loss: 0.6044 - accuracy: 0.4692\n",
      "Epoch 2/5\n",
      "3002/3002 [==============================] - 1785s 595ms/step - loss: 0.5311 - accuracy: 0.5472\n",
      "Epoch 3/5\n",
      "3002/3002 [==============================] - 1780s 593ms/step - loss: 0.4833 - accuracy: 0.5810\n",
      "Epoch 4/5\n",
      "3002/3002 [==============================] - 1796s 598ms/step - loss: 0.4554 - accuracy: 0.6265\n",
      "Epoch 5/5\n",
      "3002/3002 [==============================] - 1780s 593ms/step - loss: 0.4355 - accuracy: 0.6525\n",
      "751/751 [==============================] - 166s 220ms/step\n",
      "***Performance on Validation data***\n",
      "Accuracy  : 0.6676439232409381\n",
      "Precision : 0.6768322148596048\n",
      "f1Score : 0.644389618405144\n",
      "sensGlacoma : 0.9007501442585113\n",
      "specGlaucoma : 0.5482912332838039\n",
      "sensNormal : 0.33414436334144365\n",
      "specNormal : 0.9031361651448988\n",
      "sensOther : 0.8539325842696629\n",
      "specOther : 0.9693189480782198\n",
      "[[1561  117   55]\n",
      " [ 785  412   36]\n",
      " [ 127  127  532]]\n",
      "Results for fold 2\n",
      "Found 15008 images belonging to 3 classes.\n",
      "Found 3752 images belonging to 3 classes.\n",
      "Epoch 1/5\n",
      "3002/3002 [==============================] - 1794s 598ms/step - loss: 0.4236 - accuracy: 0.6685\n",
      "Epoch 2/5\n",
      "3002/3002 [==============================] - 1791s 596ms/step - loss: 0.4195 - accuracy: 0.6732\n",
      "Epoch 3/5\n",
      "3002/3002 [==============================] - 1798s 599ms/step - loss: 0.4105 - accuracy: 0.6858\n",
      "Epoch 4/5\n",
      "3002/3002 [==============================] - 1790s 596ms/step - loss: 0.4038 - accuracy: 0.6901\n",
      "Epoch 5/5\n",
      "3002/3002 [==============================] - 1816s 605ms/step - loss: 0.3982 - accuracy: 0.6941\n",
      "751/751 [==============================] - 160s 213ms/step\n",
      "***Performance on Validation data***\n",
      "Accuracy  : 0.7126865671641791\n",
      "Precision : 0.7127168196994913\n",
      "f1Score : 0.7119718749700229\n",
      "sensGlacoma : 0.7864974033467974\n",
      "specGlaucoma : 0.7632491332342743\n",
      "sensNormal : 0.5944849959448499\n",
      "specNormal : 0.8161969035331481\n",
      "sensOther : 0.8083916083916084\n",
      "specOther : 0.9538098449089684\n",
      "[[1363  284   86]\n",
      " [ 449  733   51]\n",
      " [  29  179  578]]\n",
      "Results for fold 3\n",
      "Found 15008 images belonging to 3 classes.\n",
      "Found 3752 images belonging to 3 classes.\n",
      "Epoch 1/5\n",
      "3002/3002 [==============================] - 1845s 614ms/step - loss: 0.3979 - accuracy: 0.6954\n",
      "Epoch 2/5\n",
      "3002/3002 [==============================] - 1848s 615ms/step - loss: 0.3997 - accuracy: 0.6896\n",
      "Epoch 3/5\n",
      "3002/3002 [==============================] - 1849s 616ms/step - loss: 0.3954 - accuracy: 0.6979\n",
      "Epoch 4/5\n",
      "3002/3002 [==============================] - 1859s 619ms/step - loss: 0.3888 - accuracy: 0.6996\n",
      "Epoch 5/5\n",
      "3002/3002 [==============================] - 1866s 622ms/step - loss: 0.3823 - accuracy: 0.7067\n",
      "751/751 [==============================] - 168s 224ms/step\n",
      "***Performance on Validation data***\n",
      "Accuracy  : 0.7228144989339019\n",
      "Precision : 0.7232635749454073\n",
      "f1Score : 0.7223653365597157\n",
      "sensGlacoma : 0.7778418926716676\n",
      "specGlaucoma : 0.7553244180287271\n",
      "sensNormal : 0.6147607461476075\n",
      "specNormal : 0.8308852719333069\n",
      "sensOther : 0.8347107438016529\n",
      "specOther : 0.959541469993257\n",
      "[[1348  299   86]\n",
      " [ 441  758   34]\n",
      " [  53  127  606]]\n",
      "Results for fold 4\n",
      "Found 15008 images belonging to 3 classes.\n",
      "Found 3752 images belonging to 3 classes.\n",
      "Epoch 1/5\n",
      "3002/3002 [==============================] - 1784s 594ms/step - loss: 0.3774 - accuracy: 0.7131\n",
      "Epoch 2/5\n",
      "3002/3002 [==============================] - 1771s 590ms/step - loss: 0.3733 - accuracy: 0.7170\n",
      "Epoch 3/5\n",
      "3002/3002 [==============================] - 1779s 592ms/step - loss: 0.3737 - accuracy: 0.7197\n",
      "Epoch 4/5\n",
      "3002/3002 [==============================] - 1776s 592ms/step - loss: 0.3703 - accuracy: 0.7215\n",
      "Epoch 5/5\n",
      "3002/3002 [==============================] - 1784s 594ms/step - loss: 0.3719 - accuracy: 0.7207\n",
      "751/751 [==============================] - 150s 200ms/step\n",
      "***Performance on Validation data***\n",
      "Accuracy  : 0.7161513859275054\n",
      "Precision : 0.7141087966243881\n",
      "f1Score : 0.7146376402742887\n",
      "sensGlacoma : 0.7841892671667628\n",
      "specGlaucoma : 0.7662209014363547\n",
      "sensNormal : 0.578264395782644\n",
      "specNormal : 0.8225486304088924\n",
      "sensOther : 0.8081471747700394\n",
      "specOther : 0.9507754551584626\n",
      "[[1359  288   86]\n",
      " [ 460  713   60]\n",
      " [  12  159  615]]\n",
      "Results for fold 5\n",
      "Found 15008 images belonging to 3 classes.\n",
      "Found 3752 images belonging to 3 classes.\n",
      "Epoch 1/5\n",
      "3002/3002 [==============================] - 1783s 594ms/step - loss: 0.3726 - accuracy: 0.7164\n",
      "Epoch 2/5\n",
      "3002/3002 [==============================] - 1781s 593ms/step - loss: 0.3693 - accuracy: 0.7191\n",
      "Epoch 3/5\n",
      "3002/3002 [==============================] - 1792s 597ms/step - loss: 0.3645 - accuracy: 0.7269\n",
      "Epoch 4/5\n",
      "3002/3002 [==============================] - 1783s 594ms/step - loss: 0.3663 - accuracy: 0.7227\n",
      "Epoch 5/5\n",
      "3002/3002 [==============================] - 1774s 591ms/step - loss: 0.3647 - accuracy: 0.7275\n",
      "751/751 [==============================] - 159s 212ms/step\n",
      "***Performance on Validation data***\n",
      "Accuracy  : 0.720682302771855\n",
      "Precision : 0.7151220651182898\n",
      "f1Score : 0.7156475460072023\n",
      "sensGlacoma : 0.7956120092378753\n",
      "specGlaucoma : 0.754950495049505\n",
      "sensNormal : 0.5401459854014599\n",
      "specNormal : 0.8539102818578801\n",
      "sensOther : 0.7810650887573964\n",
      "specOther : 0.9376053962900506\n",
      "[[1378  262   92]\n",
      " [ 474  666   93]\n",
      " [  21  106  660]]\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "skf.get_n_splits(X, Y)\n",
    "foldNumber=0\n",
    "for train_index, val_index in skf.split(X, Y):\n",
    "    transferAllClassBetweenFolders('validation', 'train', 1.0)\n",
    "    foldNumber+=1\n",
    "    print(\"Results for fold\",foldNumber)\n",
    "    X_train, X_val = X[train_index], X[val_index]\n",
    "    Y_train, Y_val = Y[train_index], Y[val_index]\n",
    "    for eachIndex in range(len(X_val)):\n",
    "        classLabel=''\n",
    "        if(Y_val[eachIndex]==0):\n",
    "            classLabel=classLabels[0]\n",
    "        elif(Y_val[eachIndex]==1):\n",
    "            classLabel=classLabels[1]\n",
    "        else:\n",
    "            classLabel=classLabels[2]   \n",
    "        #Then, copy the validation images to the validation folder\n",
    "        shutil.move(datasetFolderName+'/train/'+classLabel+'/'+X_val[eachIndex], \n",
    "                    datasetFolderName+'/validation/'+classLabel+'/'+X_val[eachIndex])\n",
    "    train_datagen = ImageDataGenerator(\n",
    "                rescale=1./255,\n",
    "        \t\tzoom_range=0.20,\n",
    "            \tfill_mode=\"nearest\"\n",
    "                )\n",
    "    validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    \n",
    "    #Start ImageClassification Model\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_path,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        subset='training')\n",
    "\n",
    "    validation_generator = validation_datagen.flow_from_directory(\n",
    "            validation_path,\n",
    "            target_size=(img_rows, img_cols),\n",
    "            batch_size=batch_size,\n",
    "            class_mode=None,  # only data, no labels\n",
    "            shuffle=False)   \n",
    "    \n",
    "    # fit model\n",
    "    history=model.fit(train_generator, \n",
    "                        epochs=epoch)\n",
    "    \n",
    "    predictions = model.predict(validation_generator, verbose=1)\n",
    "    yPredictions = np.argmax(predictions, axis=1)\n",
    "    true_classes = validation_generator.classes\n",
    "    # evaluate validation performance\n",
    "    print(\"***Performance on Validation data***\")    \n",
    "    valAcc, valPrec, valFScore, valsensGlaucoma, valspecGlaucoma, valsensNormal, valspecNormal, valsensOther, valspecOther = my_metrics(true_classes, yPredictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============TEST RESULTS============\n",
      "Found 4688 images belonging to 3 classes.\n",
      "938/938 [==============================] - 172s 183ms/step\n",
      "Accuracy  : 0.7199232081911263\n",
      "Precision : 0.7147822133899457\n",
      "f1Score : 0.7139219909685126\n",
      "sensGlacoma : 0.8143187066974595\n",
      "specGlaucoma : 0.7415774871185097\n",
      "sensNormal : 0.5288773523685918\n",
      "specNormal : 0.8646329837940896\n",
      "sensOther : 0.7722868217054264\n",
      "specOther : 0.9365893146249326\n",
      "[[1763  280  122]\n",
      " [ 613  815  113]\n",
      " [  39  146  797]]\n"
     ]
    }
   ],
   "source": [
    "print(\"==============TEST RESULTS============\")\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        test_path,\n",
    "        target_size=(img_rows, img_cols),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False) \n",
    "predictions = model.predict(test_generator, verbose=1)\n",
    "yPredictions = np.argmax(predictions, axis=1)\n",
    "true_classes = test_generator.classes\n",
    "\n",
    "testAcc,testPrec, testFScore, valsensGlaucoma, valspecGlaucoma, valsensNormal, valspecNormal, valsensOther, valspecOther = my_metrics(true_classes, yPredictions)\n",
    "model.save(MODEL_FILENAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
